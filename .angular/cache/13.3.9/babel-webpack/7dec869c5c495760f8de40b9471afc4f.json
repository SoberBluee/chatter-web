{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/ethandonovan/Documents/GitHub/chatter-web/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\n\nconst util = require('util');\n\nconst crypto = require('crypto');\n\nconst fs = require('fs');\n\nconst Minipass = require('minipass');\n\nconst path = require('path');\n\nconst ssri = require('ssri');\n\nconst uniqueFilename = require('unique-filename');\n\nconst {\n  disposer\n} = require('./util/disposer');\n\nconst contentPath = require('./content/path');\n\nconst fixOwner = require('./util/fix-owner');\n\nconst hashToSegments = require('./util/hash-to-segments');\n\nconst indexV = require('../package.json')['cache-version'].index;\n\nconst moveFile = require('@npmcli/move-file');\n\nconst _rimraf = require('rimraf');\n\nconst rimraf = util.promisify(_rimraf);\nrimraf.sync = _rimraf.sync;\nconst appendFile = util.promisify(fs.appendFile);\nconst readFile = util.promisify(fs.readFile);\nconst readdir = util.promisify(fs.readdir);\nconst writeFile = util.promisify(fs.writeFile);\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor(cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`);\n    this.code = 'ENOENT';\n    this.cache = cache;\n    this.key = key;\n  }\n\n};\nmodule.exports.compact = compact;\n\nfunction compact(_x, _x2, _x3) {\n  return _compact.apply(this, arguments);\n}\n\nfunction _compact() {\n  _compact = _asyncToGenerator(function* (cache, key, matchFn, opts = {}) {\n    const bucket = bucketPath(cache, key);\n    const entries = yield bucketEntries(bucket);\n    const newEntries = []; // we loop backwards because the bottom-most result is the newest\n    // since we add new entries with appendFile\n\n    for (let i = entries.length - 1; i >= 0; --i) {\n      const entry = entries[i]; // a null integrity could mean either a delete was appended\n      // or the user has simply stored an index that does not map\n      // to any content. we determine if the user wants to keep the\n      // null integrity based on the validateEntry function passed in options.\n      // if the integrity is null and no validateEntry is provided, we break\n      // as we consider the null integrity to be a deletion of everything\n      // that came before it.\n\n      if (entry.integrity === null && !opts.validateEntry) break; // if this entry is valid, and it is either the first entry or\n      // the newEntries array doesn't already include an entry that\n      // matches this one based on the provided matchFn, then we add\n      // it to the beginning of our list\n\n      if ((!opts.validateEntry || opts.validateEntry(entry) === true) && (newEntries.length === 0 || !newEntries.find(oldEntry => matchFn(oldEntry, entry)))) newEntries.unshift(entry);\n    }\n\n    const newIndex = '\\n' + newEntries.map(entry => {\n      const stringified = JSON.stringify(entry);\n      const hash = hashEntry(stringified);\n      return `${hash}\\t${stringified}`;\n    }).join('\\n');\n\n    const setup = /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator(function* () {\n        const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix);\n        yield fixOwner.mkdirfix(cache, path.dirname(target));\n        return {\n          target,\n          moved: false\n        };\n      });\n\n      return function setup() {\n        return _ref.apply(this, arguments);\n      };\n    }();\n\n    const teardown = /*#__PURE__*/function () {\n      var _ref2 = _asyncToGenerator(function* (tmp) {\n        if (!tmp.moved) return rimraf(tmp.target);\n      });\n\n      return function teardown(_x4) {\n        return _ref2.apply(this, arguments);\n      };\n    }();\n\n    const write = /*#__PURE__*/function () {\n      var _ref3 = _asyncToGenerator(function* (tmp) {\n        yield writeFile(tmp.target, newIndex, {\n          flag: 'wx'\n        });\n        yield fixOwner.mkdirfix(cache, path.dirname(bucket)); // we use @npmcli/move-file directly here because we\n        // want to overwrite the existing file\n\n        yield moveFile(tmp.target, bucket);\n        tmp.moved = true;\n\n        try {\n          yield fixOwner.chownr(cache, bucket);\n        } catch (err) {\n          if (err.code !== 'ENOENT') throw err;\n        }\n      });\n\n      return function write(_x5) {\n        return _ref3.apply(this, arguments);\n      };\n    }(); // write the file atomically\n\n\n    yield disposer(setup(), teardown, write); // we reverse the list we generated such that the newest\n    // entries come first in order to make looping through them easier\n    // the true passed to formatEntry tells it to keep null\n    // integrity values, if they made it this far it's because\n    // validateEntry returned true, and as such we should return it\n\n    return newEntries.reverse().map(entry => formatEntry(cache, entry, true));\n  });\n  return _compact.apply(this, arguments);\n}\n\nmodule.exports.insert = insert;\n\nfunction insert(cache, key, integrity, opts = {}) {\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  return fixOwner.mkdirfix(cache, path.dirname(bucket)).then(() => {\n    const stringified = JSON.stringify(entry); // NOTE - Cleverness ahoy!\n    //\n    // This works because it's tremendously unlikely for an entry to corrupt\n    // another while still preserving the string length of the JSON in\n    // question. So, we just slap the length in there and verify it on read.\n    //\n    // Thanks to @isaacs for the whiteboarding session that ended up with\n    // this.\n\n    return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n  }).then(() => fixOwner.chownr(cache, bucket)).catch(err => {\n    if (err.code === 'ENOENT') return undefined;\n    throw err; // There's a class of race conditions that happen when things get deleted\n    // during fixOwner, or between the two mkdirfix/chownr calls.\n    //\n    // It's perfectly fine to just not bother in those cases and lie\n    // that the index entry was written. Because it's a cache.\n  }).then(() => {\n    return formatEntry(cache, entry);\n  });\n}\n\nmodule.exports.insert.sync = insertSync;\n\nfunction insertSync(cache, key, integrity, opts = {}) {\n  const {\n    metadata,\n    size\n  } = opts;\n  const bucket = bucketPath(cache, key);\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata\n  };\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket));\n  const stringified = JSON.stringify(entry);\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`);\n\n  try {\n    fixOwner.chownr.sync(cache, bucket);\n  } catch (err) {\n    if (err.code !== 'ENOENT') throw err;\n  }\n\n  return formatEntry(cache, entry);\n}\n\nmodule.exports.find = find;\n\nfunction find(cache, key) {\n  const bucket = bucketPath(cache, key);\n  return bucketEntries(bucket).then(entries => {\n    return entries.reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  }).catch(err => {\n    if (err.code === 'ENOENT') return null;else throw err;\n  });\n}\n\nmodule.exports.find.sync = findSync;\n\nfunction findSync(cache, key) {\n  const bucket = bucketPath(cache, key);\n\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key) return formatEntry(cache, next);else return latest;\n    }, null);\n  } catch (err) {\n    if (err.code === 'ENOENT') return null;else throw err;\n  }\n}\n\nmodule.exports.delete = del;\n\nfunction del(cache, key, opts = {}) {\n  if (!opts.removeFully) return insert(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf(bucket);\n}\n\nmodule.exports.delete.sync = delSync;\n\nfunction delSync(cache, key, opts = {}) {\n  if (!opts.removeFully) return insertSync(cache, key, null, opts);\n  const bucket = bucketPath(cache, key);\n  return rimraf.sync(bucket);\n}\n\nmodule.exports.lsStream = lsStream;\n\nfunction lsStream(cache) {\n  const indexDir = bucketDir(cache);\n  const stream = new Minipass({\n    objectMode: true\n  });\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(buckets.map(bucket => {\n    const bucketPath = path.join(indexDir, bucket);\n    return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(subbuckets.map(subbucket => {\n      const subbucketPath = path.join(bucketPath, subbucket); // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n\n      return readdirOrEmpty(subbucketPath).then(entries => Promise.all(entries.map(entry => {\n        const entryPath = path.join(subbucketPath, entry);\n        return bucketEntries(entryPath).then(entries => // using a Map here prevents duplicate keys from\n        // showing up twice, I guess?\n        entries.reduce((acc, entry) => {\n          acc.set(entry.key, entry);\n          return acc;\n        }, new Map())).then(reduced => {\n          // reduced is a map of key => entry\n          for (const entry of reduced.values()) {\n            const formatted = formatEntry(cache, entry);\n            if (formatted) stream.write(formatted);\n          }\n        }).catch(err => {\n          if (err.code === 'ENOENT') return undefined;\n          throw err;\n        });\n      })));\n    })));\n  }))).then(() => stream.end(), err => stream.emit('error', err));\n  return stream;\n}\n\nmodule.exports.ls = ls;\n\nfunction ls(cache) {\n  return lsStream(cache).collect().then(entries => entries.reduce((acc, xs) => {\n    acc[xs.key] = xs;\n    return acc;\n  }, {}));\n}\n\nmodule.exports.bucketEntries = bucketEntries;\n\nfunction bucketEntries(bucket, filter) {\n  return readFile(bucket, 'utf8').then(data => _bucketEntries(data, filter));\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync;\n\nfunction bucketEntriesSync(bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8');\n  return _bucketEntries(data, filter);\n}\n\nfunction _bucketEntries(data, filter) {\n  const entries = [];\n  data.split('\\n').forEach(entry => {\n    if (!entry) return;\n    const pieces = entry.split('\\t');\n\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return;\n    }\n\n    let obj;\n\n    try {\n      obj = JSON.parse(pieces[1]);\n    } catch (e) {\n      // Entry is corrupted!\n      return;\n    }\n\n    if (obj) entries.push(obj);\n  });\n  return entries;\n}\n\nmodule.exports.bucketDir = bucketDir;\n\nfunction bucketDir(cache) {\n  return path.join(cache, `index-v${indexV}`);\n}\n\nmodule.exports.bucketPath = bucketPath;\n\nfunction bucketPath(cache, key) {\n  const hashed = hashKey(key);\n  return path.join.apply(path, [bucketDir(cache)].concat(hashToSegments(hashed)));\n}\n\nmodule.exports.hashKey = hashKey;\n\nfunction hashKey(key) {\n  return hash(key, 'sha256');\n}\n\nmodule.exports.hashEntry = hashEntry;\n\nfunction hashEntry(str) {\n  return hash(str, 'sha1');\n}\n\nfunction hash(str, digest) {\n  return crypto.createHash(digest).update(str).digest('hex');\n}\n\nfunction formatEntry(cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll) return null;\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata\n  };\n}\n\nfunction readdirOrEmpty(dir) {\n  return readdir(dir).catch(err => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR') return [];\n    throw err;\n  });\n}","map":{"version":3,"sources":["/Users/ethandonovan/Documents/GitHub/chatter-web/node_modules/cacache/lib/entry-index.js"],"names":["util","require","crypto","fs","Minipass","path","ssri","uniqueFilename","disposer","contentPath","fixOwner","hashToSegments","indexV","index","moveFile","_rimraf","rimraf","promisify","sync","appendFile","readFile","readdir","writeFile","module","exports","NotFoundError","Error","constructor","cache","key","code","compact","matchFn","opts","bucket","bucketPath","entries","bucketEntries","newEntries","i","length","entry","integrity","validateEntry","find","oldEntry","unshift","newIndex","map","stringified","JSON","stringify","hash","hashEntry","join","setup","target","tmpPrefix","mkdirfix","dirname","moved","teardown","tmp","write","flag","chownr","err","reverse","formatEntry","insert","metadata","size","time","Date","now","then","catch","undefined","insertSync","appendFileSync","reduce","latest","next","findSync","bucketEntriesSync","delete","del","removeFully","delSync","lsStream","indexDir","bucketDir","stream","objectMode","readdirOrEmpty","buckets","Promise","all","subbuckets","subbucket","subbucketPath","entryPath","acc","set","Map","reduced","values","formatted","end","emit","ls","collect","xs","filter","data","_bucketEntries","readFileSync","split","forEach","pieces","obj","parse","e","push","hashed","hashKey","apply","concat","str","digest","createHash","update","keepAll","dir"],"mappings":"AAAA;;;;AAEA,MAAMA,IAAI,GAAGC,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMC,MAAM,GAAGD,OAAO,CAAC,QAAD,CAAtB;;AACA,MAAME,EAAE,GAAGF,OAAO,CAAC,IAAD,CAAlB;;AACA,MAAMG,QAAQ,GAAGH,OAAO,CAAC,UAAD,CAAxB;;AACA,MAAMI,IAAI,GAAGJ,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMK,IAAI,GAAGL,OAAO,CAAC,MAAD,CAApB;;AACA,MAAMM,cAAc,GAAGN,OAAO,CAAC,iBAAD,CAA9B;;AAEA,MAAM;AAAEO,EAAAA;AAAF,IAAeP,OAAO,CAAC,iBAAD,CAA5B;;AACA,MAAMQ,WAAW,GAAGR,OAAO,CAAC,gBAAD,CAA3B;;AACA,MAAMS,QAAQ,GAAGT,OAAO,CAAC,kBAAD,CAAxB;;AACA,MAAMU,cAAc,GAAGV,OAAO,CAAC,yBAAD,CAA9B;;AACA,MAAMW,MAAM,GAAGX,OAAO,CAAC,iBAAD,CAAP,CAA2B,eAA3B,EAA4CY,KAA3D;;AACA,MAAMC,QAAQ,GAAGb,OAAO,CAAC,mBAAD,CAAxB;;AACA,MAAMc,OAAO,GAAGd,OAAO,CAAC,QAAD,CAAvB;;AACA,MAAMe,MAAM,GAAGhB,IAAI,CAACiB,SAAL,CAAeF,OAAf,CAAf;AACAC,MAAM,CAACE,IAAP,GAAcH,OAAO,CAACG,IAAtB;AAEA,MAAMC,UAAU,GAAGnB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACgB,UAAlB,CAAnB;AACA,MAAMC,QAAQ,GAAGpB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACiB,QAAlB,CAAjB;AACA,MAAMC,OAAO,GAAGrB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACkB,OAAlB,CAAhB;AACA,MAAMC,SAAS,GAAGtB,IAAI,CAACiB,SAAL,CAAed,EAAE,CAACmB,SAAlB,CAAlB;AAEAC,MAAM,CAACC,OAAP,CAAeC,aAAf,GAA+B,MAAMA,aAAN,SAA4BC,KAA5B,CAAkC;AAC/DC,EAAAA,WAAW,CAAEC,KAAF,EAASC,GAAT,EAAc;AACvB,UAAO,sBAAqBA,GAAI,aAAYD,KAAM,EAAlD;AACA,SAAKE,IAAL,GAAY,QAAZ;AACA,SAAKF,KAAL,GAAaA,KAAb;AACA,SAAKC,GAAL,GAAWA,GAAX;AACD;;AAN8D,CAAjE;AASAN,MAAM,CAACC,OAAP,CAAeO,OAAf,GAAyBA,OAAzB;;SAEeA,O;;;;;+BAAf,WAAwBH,KAAxB,EAA+BC,GAA/B,EAAoCG,OAApC,EAA6CC,IAAI,GAAG,EAApD,EAAwD;AACtD,UAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,UAAMO,OAAO,SAASC,aAAa,CAACH,MAAD,CAAnC;AACA,UAAMI,UAAU,GAAG,EAAnB,CAHsD,CAItD;AACA;;AACA,SAAK,IAAIC,CAAC,GAAGH,OAAO,CAACI,MAAR,GAAiB,CAA9B,EAAiCD,CAAC,IAAI,CAAtC,EAAyC,EAAEA,CAA3C,EAA8C;AAC5C,YAAME,KAAK,GAAGL,OAAO,CAACG,CAAD,CAArB,CAD4C,CAE5C;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,UAAIE,KAAK,CAACC,SAAN,KAAoB,IAApB,IAA4B,CAACT,IAAI,CAACU,aAAtC,EACE,MAV0C,CAY5C;AACA;AACA;AACA;;AACA,UAAI,CAAC,CAACV,IAAI,CAACU,aAAN,IAAuBV,IAAI,CAACU,aAAL,CAAmBF,KAAnB,MAA8B,IAAtD,MACDH,UAAU,CAACE,MAAX,KAAsB,CAAtB,IACC,CAACF,UAAU,CAACM,IAAX,CAAiBC,QAAD,IAAcb,OAAO,CAACa,QAAD,EAAWJ,KAAX,CAArC,CAFD,CAAJ,EAGEH,UAAU,CAACQ,OAAX,CAAmBL,KAAnB;AACH;;AAED,UAAMM,QAAQ,GAAG,OAAOT,UAAU,CAACU,GAAX,CAAgBP,KAAD,IAAW;AAChD,YAAMQ,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB;AACA,YAAMW,IAAI,GAAGC,SAAS,CAACJ,WAAD,CAAtB;AACA,aAAQ,GAAEG,IAAK,KAAIH,WAAY,EAA/B;AACD,KAJuB,EAIrBK,IAJqB,CAIhB,IAJgB,CAAxB;;AAMA,UAAMC,KAAK;AAAA,mCAAG,aAAY;AACxB,cAAMC,MAAM,GAAGjD,cAAc,CAACF,IAAI,CAACiD,IAAL,CAAU1B,KAAV,EAAiB,KAAjB,CAAD,EAA0BK,IAAI,CAACwB,SAA/B,CAA7B;AACA,cAAM/C,QAAQ,CAACgD,QAAT,CAAkB9B,KAAlB,EAAyBvB,IAAI,CAACsD,OAAL,CAAaH,MAAb,CAAzB,CAAN;AACA,eAAO;AACLA,UAAAA,MADK;AAELI,UAAAA,KAAK,EAAE;AAFF,SAAP;AAID,OAPU;;AAAA,sBAALL,KAAK;AAAA;AAAA;AAAA,OAAX;;AASA,UAAMM,QAAQ;AAAA,oCAAG,WAAOC,GAAP,EAAe;AAC9B,YAAI,CAACA,GAAG,CAACF,KAAT,EACE,OAAO5C,MAAM,CAAC8C,GAAG,CAACN,MAAL,CAAb;AACH,OAHa;;AAAA,sBAARK,QAAQ;AAAA;AAAA;AAAA,OAAd;;AAKA,UAAME,KAAK;AAAA,oCAAG,WAAOD,GAAP,EAAe;AAC3B,cAAMxC,SAAS,CAACwC,GAAG,CAACN,MAAL,EAAaT,QAAb,EAAuB;AAAEiB,UAAAA,IAAI,EAAE;AAAR,SAAvB,CAAf;AACA,cAAMtD,QAAQ,CAACgD,QAAT,CAAkB9B,KAAlB,EAAyBvB,IAAI,CAACsD,OAAL,CAAazB,MAAb,CAAzB,CAAN,CAF2B,CAG3B;AACA;;AACA,cAAMpB,QAAQ,CAACgD,GAAG,CAACN,MAAL,EAAatB,MAAb,CAAd;AACA4B,QAAAA,GAAG,CAACF,KAAJ,GAAY,IAAZ;;AACA,YAAI;AACF,gBAAMlD,QAAQ,CAACuD,MAAT,CAAgBrC,KAAhB,EAAuBM,MAAvB,CAAN;AACD,SAFD,CAEE,OAAOgC,GAAP,EAAY;AACZ,cAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,MAAMoC,GAAN;AACH;AACF,OAbU;;AAAA,sBAALH,KAAK;AAAA;AAAA;AAAA,OAAX,CAhDsD,CA+DtD;;;AACA,UAAMvD,QAAQ,CAAC+C,KAAK,EAAN,EAAUM,QAAV,EAAoBE,KAApB,CAAd,CAhEsD,CAkEtD;AACA;AACA;AACA;AACA;;AACA,WAAOzB,UAAU,CAAC6B,OAAX,GAAqBnB,GAArB,CAA0BP,KAAD,IAAW2B,WAAW,CAACxC,KAAD,EAAQa,KAAR,EAAe,IAAf,CAA/C,CAAP;AACD,G;;;;AAEDlB,MAAM,CAACC,OAAP,CAAe6C,MAAf,GAAwBA,MAAxB;;AAEA,SAASA,MAAT,CAAiBzC,KAAjB,EAAwBC,GAAxB,EAA6Ba,SAA7B,EAAwCT,IAAI,GAAG,EAA/C,EAAmD;AACjD,QAAM;AAAEqC,IAAAA,QAAF;AAAYC,IAAAA;AAAZ,MAAqBtC,IAA3B;AACA,QAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,QAAMY,KAAK,GAAG;AACZZ,IAAAA,GADY;AAEZa,IAAAA,SAAS,EAAEA,SAAS,IAAIpC,IAAI,CAAC6C,SAAL,CAAeT,SAAf,CAFZ;AAGZ8B,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZH,IAAAA,IAJY;AAKZD,IAAAA;AALY,GAAd;AAOA,SAAO5D,QAAQ,CACZgD,QADI,CACK9B,KADL,EACYvB,IAAI,CAACsD,OAAL,CAAazB,MAAb,CADZ,EAEJyC,IAFI,CAEC,MAAM;AACV,UAAM1B,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB,CADU,CAEV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,WAAOtB,UAAU,CAACe,MAAD,EAAU,KAAImB,SAAS,CAACJ,WAAD,CAAc,KAAIA,WAAY,EAArD,CAAjB;AACD,GAbI,EAcJ0B,IAdI,CAcC,MAAMjE,QAAQ,CAACuD,MAAT,CAAgBrC,KAAhB,EAAuBM,MAAvB,CAdP,EAeJ0C,KAfI,CAeGV,GAAD,IAAS;AACd,QAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,OAAO+C,SAAP;AAEF,UAAMX,GAAN,CAJc,CAKd;AACA;AACA;AACA;AACA;AACD,GAzBI,EA0BJS,IA1BI,CA0BC,MAAM;AACV,WAAOP,WAAW,CAACxC,KAAD,EAAQa,KAAR,CAAlB;AACD,GA5BI,CAAP;AA6BD;;AAEDlB,MAAM,CAACC,OAAP,CAAe6C,MAAf,CAAsBnD,IAAtB,GAA6B4D,UAA7B;;AAEA,SAASA,UAAT,CAAqBlD,KAArB,EAA4BC,GAA5B,EAAiCa,SAAjC,EAA4CT,IAAI,GAAG,EAAnD,EAAuD;AACrD,QAAM;AAAEqC,IAAAA,QAAF;AAAYC,IAAAA;AAAZ,MAAqBtC,IAA3B;AACA,QAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,QAAMY,KAAK,GAAG;AACZZ,IAAAA,GADY;AAEZa,IAAAA,SAAS,EAAEA,SAAS,IAAIpC,IAAI,CAAC6C,SAAL,CAAeT,SAAf,CAFZ;AAGZ8B,IAAAA,IAAI,EAAEC,IAAI,CAACC,GAAL,EAHM;AAIZH,IAAAA,IAJY;AAKZD,IAAAA;AALY,GAAd;AAOA5D,EAAAA,QAAQ,CAACgD,QAAT,CAAkBxC,IAAlB,CAAuBU,KAAvB,EAA8BvB,IAAI,CAACsD,OAAL,CAAazB,MAAb,CAA9B;AACA,QAAMe,WAAW,GAAGC,IAAI,CAACC,SAAL,CAAeV,KAAf,CAApB;AACAtC,EAAAA,EAAE,CAAC4E,cAAH,CAAkB7C,MAAlB,EAA2B,KAAImB,SAAS,CAACJ,WAAD,CAAc,KAAIA,WAAY,EAAtE;;AACA,MAAI;AACFvC,IAAAA,QAAQ,CAACuD,MAAT,CAAgB/C,IAAhB,CAAqBU,KAArB,EAA4BM,MAA5B;AACD,GAFD,CAEE,OAAOgC,GAAP,EAAY;AACZ,QAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,MAAMoC,GAAN;AACH;;AACD,SAAOE,WAAW,CAACxC,KAAD,EAAQa,KAAR,CAAlB;AACD;;AAEDlB,MAAM,CAACC,OAAP,CAAeoB,IAAf,GAAsBA,IAAtB;;AAEA,SAASA,IAAT,CAAehB,KAAf,EAAsBC,GAAtB,EAA2B;AACzB,QAAMK,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOQ,aAAa,CAACH,MAAD,CAAb,CACJyC,IADI,CACEvC,OAAD,IAAa;AACjB,WAAOA,OAAO,CAAC4C,MAAR,CAAe,CAACC,MAAD,EAASC,IAAT,KAAkB;AACtC,UAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAL,KAAaA,GAAzB,EACE,OAAOuC,WAAW,CAACxC,KAAD,EAAQsD,IAAR,CAAlB,CADF,KAGE,OAAOD,MAAP;AACH,KALM,EAKJ,IALI,CAAP;AAMD,GARI,EASJL,KATI,CASGV,GAAD,IAAS;AACd,QAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,OAAO,IAAP,CADF,KAGE,MAAMoC,GAAN;AACH,GAdI,CAAP;AAeD;;AAED3C,MAAM,CAACC,OAAP,CAAeoB,IAAf,CAAoB1B,IAApB,GAA2BiE,QAA3B;;AAEA,SAASA,QAAT,CAAmBvD,KAAnB,EAA0BC,GAA1B,EAA+B;AAC7B,QAAMK,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;;AACA,MAAI;AACF,WAAOuD,iBAAiB,CAAClD,MAAD,CAAjB,CAA0B8C,MAA1B,CAAiC,CAACC,MAAD,EAASC,IAAT,KAAkB;AACxD,UAAIA,IAAI,IAAIA,IAAI,CAACrD,GAAL,KAAaA,GAAzB,EACE,OAAOuC,WAAW,CAACxC,KAAD,EAAQsD,IAAR,CAAlB,CADF,KAGE,OAAOD,MAAP;AACH,KALM,EAKJ,IALI,CAAP;AAMD,GAPD,CAOE,OAAOf,GAAP,EAAY;AACZ,QAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,OAAO,IAAP,CADF,KAGE,MAAMoC,GAAN;AACH;AACF;;AAED3C,MAAM,CAACC,OAAP,CAAe6D,MAAf,GAAwBC,GAAxB;;AAEA,SAASA,GAAT,CAAc1D,KAAd,EAAqBC,GAArB,EAA0BI,IAAI,GAAG,EAAjC,EAAqC;AACnC,MAAI,CAACA,IAAI,CAACsD,WAAV,EACE,OAAOlB,MAAM,CAACzC,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAb;AAEF,QAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOb,MAAM,CAACkB,MAAD,CAAb;AACD;;AAEDX,MAAM,CAACC,OAAP,CAAe6D,MAAf,CAAsBnE,IAAtB,GAA6BsE,OAA7B;;AAEA,SAASA,OAAT,CAAkB5D,KAAlB,EAAyBC,GAAzB,EAA8BI,IAAI,GAAG,EAArC,EAAyC;AACvC,MAAI,CAACA,IAAI,CAACsD,WAAV,EACE,OAAOT,UAAU,CAAClD,KAAD,EAAQC,GAAR,EAAa,IAAb,EAAmBI,IAAnB,CAAjB;AAEF,QAAMC,MAAM,GAAGC,UAAU,CAACP,KAAD,EAAQC,GAAR,CAAzB;AACA,SAAOb,MAAM,CAACE,IAAP,CAAYgB,MAAZ,CAAP;AACD;;AAEDX,MAAM,CAACC,OAAP,CAAeiE,QAAf,GAA0BA,QAA1B;;AAEA,SAASA,QAAT,CAAmB7D,KAAnB,EAA0B;AACxB,QAAM8D,QAAQ,GAAGC,SAAS,CAAC/D,KAAD,CAA1B;AACA,QAAMgE,MAAM,GAAG,IAAIxF,QAAJ,CAAa;AAAEyF,IAAAA,UAAU,EAAE;AAAd,GAAb,CAAf;AAEAC,EAAAA,cAAc,CAACJ,QAAD,CAAd,CAAyBf,IAAzB,CAA8BoB,OAAO,IAAIC,OAAO,CAACC,GAAR,CACvCF,OAAO,CAAC/C,GAAR,CAAYd,MAAM,IAAI;AACpB,UAAMC,UAAU,GAAG9B,IAAI,CAACiD,IAAL,CAAUoC,QAAV,EAAoBxD,MAApB,CAAnB;AACA,WAAO4D,cAAc,CAAC3D,UAAD,CAAd,CAA2BwC,IAA3B,CAAgCuB,UAAU,IAAIF,OAAO,CAACC,GAAR,CACnDC,UAAU,CAAClD,GAAX,CAAemD,SAAS,IAAI;AAC1B,YAAMC,aAAa,GAAG/F,IAAI,CAACiD,IAAL,CAAUnB,UAAV,EAAsBgE,SAAtB,CAAtB,CAD0B,CAG1B;;AACA,aAAOL,cAAc,CAACM,aAAD,CAAd,CAA8BzB,IAA9B,CAAmCvC,OAAO,IAAI4D,OAAO,CAACC,GAAR,CACnD7D,OAAO,CAACY,GAAR,CAAYP,KAAK,IAAI;AACnB,cAAM4D,SAAS,GAAGhG,IAAI,CAACiD,IAAL,CAAU8C,aAAV,EAAyB3D,KAAzB,CAAlB;AACA,eAAOJ,aAAa,CAACgE,SAAD,CAAb,CAAyB1B,IAAzB,CAA8BvC,OAAO,IAC1C;AACA;AACAA,QAAAA,OAAO,CAAC4C,MAAR,CAAe,CAACsB,GAAD,EAAM7D,KAAN,KAAgB;AAC7B6D,UAAAA,GAAG,CAACC,GAAJ,CAAQ9D,KAAK,CAACZ,GAAd,EAAmBY,KAAnB;AACA,iBAAO6D,GAAP;AACD,SAHD,EAGG,IAAIE,GAAJ,EAHH,CAHK,EAOL7B,IAPK,CAOA8B,OAAO,IAAI;AAChB;AACA,eAAK,MAAMhE,KAAX,IAAoBgE,OAAO,CAACC,MAAR,EAApB,EAAsC;AACpC,kBAAMC,SAAS,GAAGvC,WAAW,CAACxC,KAAD,EAAQa,KAAR,CAA7B;AACA,gBAAIkE,SAAJ,EACEf,MAAM,CAAC7B,KAAP,CAAa4C,SAAb;AACH;AACF,SAdM,EAcJ/B,KAdI,CAcEV,GAAG,IAAI;AACd,cAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAjB,EACE,OAAO+C,SAAP;AACF,gBAAMX,GAAN;AACD,SAlBM,CAAP;AAmBD,OArBD,CADmD,CAA9C,CAAP;AAwBD,KA5BD,CADmD,CAA9C,CAAP;AA+BD,GAjCD,CADuC,CAAzC,EAoCGS,IApCH,CAqCI,MAAMiB,MAAM,CAACgB,GAAP,EArCV,EAsCI1C,GAAG,IAAI0B,MAAM,CAACiB,IAAP,CAAY,OAAZ,EAAqB3C,GAArB,CAtCX;AAyCA,SAAO0B,MAAP;AACD;;AAEDrE,MAAM,CAACC,OAAP,CAAesF,EAAf,GAAoBA,EAApB;;AAEA,SAASA,EAAT,CAAalF,KAAb,EAAoB;AAClB,SAAO6D,QAAQ,CAAC7D,KAAD,CAAR,CAAgBmF,OAAhB,GAA0BpC,IAA1B,CAA+BvC,OAAO,IAC3CA,OAAO,CAAC4C,MAAR,CAAe,CAACsB,GAAD,EAAMU,EAAN,KAAa;AAC1BV,IAAAA,GAAG,CAACU,EAAE,CAACnF,GAAJ,CAAH,GAAcmF,EAAd;AACA,WAAOV,GAAP;AACD,GAHD,EAGG,EAHH,CADK,CAAP;AAMD;;AAED/E,MAAM,CAACC,OAAP,CAAea,aAAf,GAA+BA,aAA/B;;AAEA,SAASA,aAAT,CAAwBH,MAAxB,EAAgC+E,MAAhC,EAAwC;AACtC,SAAO7F,QAAQ,CAACc,MAAD,EAAS,MAAT,CAAR,CAAyByC,IAAzB,CAA+BuC,IAAD,IAAUC,cAAc,CAACD,IAAD,EAAOD,MAAP,CAAtD,CAAP;AACD;;AAED1F,MAAM,CAACC,OAAP,CAAea,aAAf,CAA6BnB,IAA7B,GAAoCkE,iBAApC;;AAEA,SAASA,iBAAT,CAA4BlD,MAA5B,EAAoC+E,MAApC,EAA4C;AAC1C,QAAMC,IAAI,GAAG/G,EAAE,CAACiH,YAAH,CAAgBlF,MAAhB,EAAwB,MAAxB,CAAb;AACA,SAAOiF,cAAc,CAACD,IAAD,EAAOD,MAAP,CAArB;AACD;;AAED,SAASE,cAAT,CAAyBD,IAAzB,EAA+BD,MAA/B,EAAuC;AACrC,QAAM7E,OAAO,GAAG,EAAhB;AACA8E,EAAAA,IAAI,CAACG,KAAL,CAAW,IAAX,EAAiBC,OAAjB,CAA0B7E,KAAD,IAAW;AAClC,QAAI,CAACA,KAAL,EACE;AAEF,UAAM8E,MAAM,GAAG9E,KAAK,CAAC4E,KAAN,CAAY,IAAZ,CAAf;;AACA,QAAI,CAACE,MAAM,CAAC,CAAD,CAAP,IAAclE,SAAS,CAACkE,MAAM,CAAC,CAAD,CAAP,CAAT,KAAyBA,MAAM,CAAC,CAAD,CAAjD,EAAsD;AACpD;AACA;AACA;AACD;;AACD,QAAIC,GAAJ;;AACA,QAAI;AACFA,MAAAA,GAAG,GAAGtE,IAAI,CAACuE,KAAL,CAAWF,MAAM,CAAC,CAAD,CAAjB,CAAN;AACD,KAFD,CAEE,OAAOG,CAAP,EAAU;AACV;AACA;AACD;;AACD,QAAIF,GAAJ,EACEpF,OAAO,CAACuF,IAAR,CAAaH,GAAb;AACH,GAnBD;AAoBA,SAAOpF,OAAP;AACD;;AAEDb,MAAM,CAACC,OAAP,CAAemE,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB/D,KAApB,EAA2B;AACzB,SAAOvB,IAAI,CAACiD,IAAL,CAAU1B,KAAV,EAAkB,UAAShB,MAAO,EAAlC,CAAP;AACD;;AAEDW,MAAM,CAACC,OAAP,CAAeW,UAAf,GAA4BA,UAA5B;;AAEA,SAASA,UAAT,CAAqBP,KAArB,EAA4BC,GAA5B,EAAiC;AAC/B,QAAM+F,MAAM,GAAGC,OAAO,CAAChG,GAAD,CAAtB;AACA,SAAOxB,IAAI,CAACiD,IAAL,CAAUwE,KAAV,CACLzH,IADK,EAEL,CAACsF,SAAS,CAAC/D,KAAD,CAAV,EAAmBmG,MAAnB,CAA0BpH,cAAc,CAACiH,MAAD,CAAxC,CAFK,CAAP;AAID;;AAEDrG,MAAM,CAACC,OAAP,CAAeqG,OAAf,GAAyBA,OAAzB;;AAEA,SAASA,OAAT,CAAkBhG,GAAlB,EAAuB;AACrB,SAAOuB,IAAI,CAACvB,GAAD,EAAM,QAAN,CAAX;AACD;;AAEDN,MAAM,CAACC,OAAP,CAAe6B,SAAf,GAA2BA,SAA3B;;AAEA,SAASA,SAAT,CAAoB2E,GAApB,EAAyB;AACvB,SAAO5E,IAAI,CAAC4E,GAAD,EAAM,MAAN,CAAX;AACD;;AAED,SAAS5E,IAAT,CAAe4E,GAAf,EAAoBC,MAApB,EAA4B;AAC1B,SAAO/H,MAAM,CACVgI,UADI,CACOD,MADP,EAEJE,MAFI,CAEGH,GAFH,EAGJC,MAHI,CAGG,KAHH,CAAP;AAID;;AAED,SAAS7D,WAAT,CAAsBxC,KAAtB,EAA6Ba,KAA7B,EAAoC2F,OAApC,EAA6C;AAC3C;AACA,MAAI,CAAC3F,KAAK,CAACC,SAAP,IAAoB,CAAC0F,OAAzB,EACE,OAAO,IAAP;AAEF,SAAO;AACLvG,IAAAA,GAAG,EAAEY,KAAK,CAACZ,GADN;AAELa,IAAAA,SAAS,EAAED,KAAK,CAACC,SAFZ;AAGLrC,IAAAA,IAAI,EAAEoC,KAAK,CAACC,SAAN,GAAkBjC,WAAW,CAACmB,KAAD,EAAQa,KAAK,CAACC,SAAd,CAA7B,GAAwDmC,SAHzD;AAILN,IAAAA,IAAI,EAAE9B,KAAK,CAAC8B,IAJP;AAKLC,IAAAA,IAAI,EAAE/B,KAAK,CAAC+B,IALP;AAMLF,IAAAA,QAAQ,EAAE7B,KAAK,CAAC6B;AANX,GAAP;AAQD;;AAED,SAASwB,cAAT,CAAyBuC,GAAzB,EAA8B;AAC5B,SAAOhH,OAAO,CAACgH,GAAD,CAAP,CAAazD,KAAb,CAAoBV,GAAD,IAAS;AACjC,QAAIA,GAAG,CAACpC,IAAJ,KAAa,QAAb,IAAyBoC,GAAG,CAACpC,IAAJ,KAAa,SAA1C,EACE,OAAO,EAAP;AAEF,UAAMoC,GAAN;AACD,GALM,CAAP;AAMD","sourcesContent":["'use strict'\n\nconst util = require('util')\nconst crypto = require('crypto')\nconst fs = require('fs')\nconst Minipass = require('minipass')\nconst path = require('path')\nconst ssri = require('ssri')\nconst uniqueFilename = require('unique-filename')\n\nconst { disposer } = require('./util/disposer')\nconst contentPath = require('./content/path')\nconst fixOwner = require('./util/fix-owner')\nconst hashToSegments = require('./util/hash-to-segments')\nconst indexV = require('../package.json')['cache-version'].index\nconst moveFile = require('@npmcli/move-file')\nconst _rimraf = require('rimraf')\nconst rimraf = util.promisify(_rimraf)\nrimraf.sync = _rimraf.sync\n\nconst appendFile = util.promisify(fs.appendFile)\nconst readFile = util.promisify(fs.readFile)\nconst readdir = util.promisify(fs.readdir)\nconst writeFile = util.promisify(fs.writeFile)\n\nmodule.exports.NotFoundError = class NotFoundError extends Error {\n  constructor (cache, key) {\n    super(`No cache entry for ${key} found in ${cache}`)\n    this.code = 'ENOENT'\n    this.cache = cache\n    this.key = key\n  }\n}\n\nmodule.exports.compact = compact\n\nasync function compact (cache, key, matchFn, opts = {}) {\n  const bucket = bucketPath(cache, key)\n  const entries = await bucketEntries(bucket)\n  const newEntries = []\n  // we loop backwards because the bottom-most result is the newest\n  // since we add new entries with appendFile\n  for (let i = entries.length - 1; i >= 0; --i) {\n    const entry = entries[i]\n    // a null integrity could mean either a delete was appended\n    // or the user has simply stored an index that does not map\n    // to any content. we determine if the user wants to keep the\n    // null integrity based on the validateEntry function passed in options.\n    // if the integrity is null and no validateEntry is provided, we break\n    // as we consider the null integrity to be a deletion of everything\n    // that came before it.\n    if (entry.integrity === null && !opts.validateEntry)\n      break\n\n    // if this entry is valid, and it is either the first entry or\n    // the newEntries array doesn't already include an entry that\n    // matches this one based on the provided matchFn, then we add\n    // it to the beginning of our list\n    if ((!opts.validateEntry || opts.validateEntry(entry) === true) &&\n      (newEntries.length === 0 ||\n        !newEntries.find((oldEntry) => matchFn(oldEntry, entry))))\n      newEntries.unshift(entry)\n  }\n\n  const newIndex = '\\n' + newEntries.map((entry) => {\n    const stringified = JSON.stringify(entry)\n    const hash = hashEntry(stringified)\n    return `${hash}\\t${stringified}`\n  }).join('\\n')\n\n  const setup = async () => {\n    const target = uniqueFilename(path.join(cache, 'tmp'), opts.tmpPrefix)\n    await fixOwner.mkdirfix(cache, path.dirname(target))\n    return {\n      target,\n      moved: false,\n    }\n  }\n\n  const teardown = async (tmp) => {\n    if (!tmp.moved)\n      return rimraf(tmp.target)\n  }\n\n  const write = async (tmp) => {\n    await writeFile(tmp.target, newIndex, { flag: 'wx' })\n    await fixOwner.mkdirfix(cache, path.dirname(bucket))\n    // we use @npmcli/move-file directly here because we\n    // want to overwrite the existing file\n    await moveFile(tmp.target, bucket)\n    tmp.moved = true\n    try {\n      await fixOwner.chownr(cache, bucket)\n    } catch (err) {\n      if (err.code !== 'ENOENT')\n        throw err\n    }\n  }\n\n  // write the file atomically\n  await disposer(setup(), teardown, write)\n\n  // we reverse the list we generated such that the newest\n  // entries come first in order to make looping through them easier\n  // the true passed to formatEntry tells it to keep null\n  // integrity values, if they made it this far it's because\n  // validateEntry returned true, and as such we should return it\n  return newEntries.reverse().map((entry) => formatEntry(cache, entry, true))\n}\n\nmodule.exports.insert = insert\n\nfunction insert (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  return fixOwner\n    .mkdirfix(cache, path.dirname(bucket))\n    .then(() => {\n      const stringified = JSON.stringify(entry)\n      // NOTE - Cleverness ahoy!\n      //\n      // This works because it's tremendously unlikely for an entry to corrupt\n      // another while still preserving the string length of the JSON in\n      // question. So, we just slap the length in there and verify it on read.\n      //\n      // Thanks to @isaacs for the whiteboarding session that ended up with\n      // this.\n      return appendFile(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n    })\n    .then(() => fixOwner.chownr(cache, bucket))\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return undefined\n\n      throw err\n      // There's a class of race conditions that happen when things get deleted\n      // during fixOwner, or between the two mkdirfix/chownr calls.\n      //\n      // It's perfectly fine to just not bother in those cases and lie\n      // that the index entry was written. Because it's a cache.\n    })\n    .then(() => {\n      return formatEntry(cache, entry)\n    })\n}\n\nmodule.exports.insert.sync = insertSync\n\nfunction insertSync (cache, key, integrity, opts = {}) {\n  const { metadata, size } = opts\n  const bucket = bucketPath(cache, key)\n  const entry = {\n    key,\n    integrity: integrity && ssri.stringify(integrity),\n    time: Date.now(),\n    size,\n    metadata,\n  }\n  fixOwner.mkdirfix.sync(cache, path.dirname(bucket))\n  const stringified = JSON.stringify(entry)\n  fs.appendFileSync(bucket, `\\n${hashEntry(stringified)}\\t${stringified}`)\n  try {\n    fixOwner.chownr.sync(cache, bucket)\n  } catch (err) {\n    if (err.code !== 'ENOENT')\n      throw err\n  }\n  return formatEntry(cache, entry)\n}\n\nmodule.exports.find = find\n\nfunction find (cache, key) {\n  const bucket = bucketPath(cache, key)\n  return bucketEntries(bucket)\n    .then((entries) => {\n      return entries.reduce((latest, next) => {\n        if (next && next.key === key)\n          return formatEntry(cache, next)\n        else\n          return latest\n      }, null)\n    })\n    .catch((err) => {\n      if (err.code === 'ENOENT')\n        return null\n      else\n        throw err\n    })\n}\n\nmodule.exports.find.sync = findSync\n\nfunction findSync (cache, key) {\n  const bucket = bucketPath(cache, key)\n  try {\n    return bucketEntriesSync(bucket).reduce((latest, next) => {\n      if (next && next.key === key)\n        return formatEntry(cache, next)\n      else\n        return latest\n    }, null)\n  } catch (err) {\n    if (err.code === 'ENOENT')\n      return null\n    else\n      throw err\n  }\n}\n\nmodule.exports.delete = del\n\nfunction del (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insert(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf(bucket)\n}\n\nmodule.exports.delete.sync = delSync\n\nfunction delSync (cache, key, opts = {}) {\n  if (!opts.removeFully)\n    return insertSync(cache, key, null, opts)\n\n  const bucket = bucketPath(cache, key)\n  return rimraf.sync(bucket)\n}\n\nmodule.exports.lsStream = lsStream\n\nfunction lsStream (cache) {\n  const indexDir = bucketDir(cache)\n  const stream = new Minipass({ objectMode: true })\n\n  readdirOrEmpty(indexDir).then(buckets => Promise.all(\n    buckets.map(bucket => {\n      const bucketPath = path.join(indexDir, bucket)\n      return readdirOrEmpty(bucketPath).then(subbuckets => Promise.all(\n        subbuckets.map(subbucket => {\n          const subbucketPath = path.join(bucketPath, subbucket)\n\n          // \"/cachename/<bucket 0xFF>/<bucket 0xFF>./*\"\n          return readdirOrEmpty(subbucketPath).then(entries => Promise.all(\n            entries.map(entry => {\n              const entryPath = path.join(subbucketPath, entry)\n              return bucketEntries(entryPath).then(entries =>\n                // using a Map here prevents duplicate keys from\n                // showing up twice, I guess?\n                entries.reduce((acc, entry) => {\n                  acc.set(entry.key, entry)\n                  return acc\n                }, new Map())\n              ).then(reduced => {\n                // reduced is a map of key => entry\n                for (const entry of reduced.values()) {\n                  const formatted = formatEntry(cache, entry)\n                  if (formatted)\n                    stream.write(formatted)\n                }\n              }).catch(err => {\n                if (err.code === 'ENOENT')\n                  return undefined\n                throw err\n              })\n            })\n          ))\n        })\n      ))\n    })\n  ))\n    .then(\n      () => stream.end(),\n      err => stream.emit('error', err)\n    )\n\n  return stream\n}\n\nmodule.exports.ls = ls\n\nfunction ls (cache) {\n  return lsStream(cache).collect().then(entries =>\n    entries.reduce((acc, xs) => {\n      acc[xs.key] = xs\n      return acc\n    }, {})\n  )\n}\n\nmodule.exports.bucketEntries = bucketEntries\n\nfunction bucketEntries (bucket, filter) {\n  return readFile(bucket, 'utf8').then((data) => _bucketEntries(data, filter))\n}\n\nmodule.exports.bucketEntries.sync = bucketEntriesSync\n\nfunction bucketEntriesSync (bucket, filter) {\n  const data = fs.readFileSync(bucket, 'utf8')\n  return _bucketEntries(data, filter)\n}\n\nfunction _bucketEntries (data, filter) {\n  const entries = []\n  data.split('\\n').forEach((entry) => {\n    if (!entry)\n      return\n\n    const pieces = entry.split('\\t')\n    if (!pieces[1] || hashEntry(pieces[1]) !== pieces[0]) {\n      // Hash is no good! Corruption or malice? Doesn't matter!\n      // EJECT EJECT\n      return\n    }\n    let obj\n    try {\n      obj = JSON.parse(pieces[1])\n    } catch (e) {\n      // Entry is corrupted!\n      return\n    }\n    if (obj)\n      entries.push(obj)\n  })\n  return entries\n}\n\nmodule.exports.bucketDir = bucketDir\n\nfunction bucketDir (cache) {\n  return path.join(cache, `index-v${indexV}`)\n}\n\nmodule.exports.bucketPath = bucketPath\n\nfunction bucketPath (cache, key) {\n  const hashed = hashKey(key)\n  return path.join.apply(\n    path,\n    [bucketDir(cache)].concat(hashToSegments(hashed))\n  )\n}\n\nmodule.exports.hashKey = hashKey\n\nfunction hashKey (key) {\n  return hash(key, 'sha256')\n}\n\nmodule.exports.hashEntry = hashEntry\n\nfunction hashEntry (str) {\n  return hash(str, 'sha1')\n}\n\nfunction hash (str, digest) {\n  return crypto\n    .createHash(digest)\n    .update(str)\n    .digest('hex')\n}\n\nfunction formatEntry (cache, entry, keepAll) {\n  // Treat null digests as deletions. They'll shadow any previous entries.\n  if (!entry.integrity && !keepAll)\n    return null\n\n  return {\n    key: entry.key,\n    integrity: entry.integrity,\n    path: entry.integrity ? contentPath(cache, entry.integrity) : undefined,\n    size: entry.size,\n    time: entry.time,\n    metadata: entry.metadata,\n  }\n}\n\nfunction readdirOrEmpty (dir) {\n  return readdir(dir).catch((err) => {\n    if (err.code === 'ENOENT' || err.code === 'ENOTDIR')\n      return []\n\n    throw err\n  })\n}\n"]},"metadata":{},"sourceType":"script"}